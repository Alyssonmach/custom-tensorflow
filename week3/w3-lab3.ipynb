{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w3_lab3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2s-dkuulOoA"
      },
      "source": [
        "# Activating custom layer\n",
        "***\n",
        "In this lab, we extend our knowledge of building custom layers by adding an activation parameter. The implementation is pretty straightforward as you'll se below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3N07jO7lnav"
      },
      "source": [
        "### Imports\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GP0o0SOlDc7"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dq0CsKElz3C"
      },
      "source": [
        "### Adding an activation layer\n",
        "***\n",
        "To use the bult-in activation in Keras, we can specify an activation parameter in the `__init__()` method of our custom layer class. From there, we can initialize it by using the `tf.keras.activations.get()` method. This takes in a string identifier that corresponds to one of the available activations in Keras. next, you can now pass in the forward computation to this activation in the `call()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3iJ6w68lzSv"
      },
      "source": [
        "from tensorflow.keras.layers  import Layer\n",
        "\n",
        "class SimpleDense(Layer):\n",
        "\n",
        "  def __init__(self, units=32, activation=None):\n",
        "\n",
        "    super(SimpleDense, self).__init__()\n",
        "    self.units = units\n",
        "    self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "\n",
        "    w_init = tf.random_normal_initializer()\n",
        "    self.w = tf.Variable(name='kernel', initial_value=w_init(shape=(input_shape[-1], self.units), dtype='float32'), trainable=True)\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(name='bias', initial_value=b_init(shape=(self.units), dtype='float32'), trainable=True)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "\n",
        "    return self.activation(tf.matmul(inputs, self.w) + self.b)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfYLjHGxmwmS"
      },
      "source": [
        "We can now pass in an activation parameter to our custom layer. The string identifier is mostly the same as the function name so 'relu' below will get `tf.keras.activations.relu`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSExJPUXmwHj",
        "outputId": "bccca190-c467-43fa-9c39-b2fd321c84ec"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "                                    SimpleDense(units=128, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(rate=0.2),\n",
        "                                    tf.keras.layers.Dense(units=10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2931 - accuracy: 0.9149\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1429 - accuracy: 0.9570\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9675\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0895 - accuracy: 0.9720\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0756 - accuracy: 0.9761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efed26f7b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJnwUg-jn7XA",
        "outputId": "cdebc294-09b9-4dec-ee49-05d295343444"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.0746 - accuracy: 0.9758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07459434121847153, 0.9757999777793884]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}